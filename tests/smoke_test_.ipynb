{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "004ae22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Inference using project root: C:\\Users\\USER\\Downloads\\machine learning\\project\\Regression_ML_EndtoEnd\n",
      "Input sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>median_sale_price</th>\n",
       "      <th>median_list_price</th>\n",
       "      <th>median_ppsf</th>\n",
       "      <th>median_list_ppsf</th>\n",
       "      <th>homes_sold</th>\n",
       "      <th>pending_sales</th>\n",
       "      <th>new_listings</th>\n",
       "      <th>inventory</th>\n",
       "      <th>median_dom</th>\n",
       "      <th>...</th>\n",
       "      <th>Median Home Value</th>\n",
       "      <th>Total Labor Force</th>\n",
       "      <th>Unemployed Population</th>\n",
       "      <th>Total School Age Population</th>\n",
       "      <th>Total School Enrollment</th>\n",
       "      <th>Median Commute Time</th>\n",
       "      <th>price</th>\n",
       "      <th>city_full</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>258528.0</td>\n",
       "      <td>259900.0</td>\n",
       "      <td>145.396160</td>\n",
       "      <td>140.979244</td>\n",
       "      <td>104.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>182900.0</td>\n",
       "      <td>10937.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>20604.0</td>\n",
       "      <td>20604.0</td>\n",
       "      <td>10007.0</td>\n",
       "      <td>255300.562038</td>\n",
       "      <td>Cincinnati, OH-KY-IN</td>\n",
       "      <td>39.0811</td>\n",
       "      <td>-84.4646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>457000.0</td>\n",
       "      <td>429000.0</td>\n",
       "      <td>253.164135</td>\n",
       "      <td>257.973734</td>\n",
       "      <td>82.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450603.296700</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ</td>\n",
       "      <td>40.7222</td>\n",
       "      <td>-74.0225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>187250.0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>99.965760</td>\n",
       "      <td>109.198464</td>\n",
       "      <td>94.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>...</td>\n",
       "      <td>161000.0</td>\n",
       "      <td>31265.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>52357.0</td>\n",
       "      <td>52357.0</td>\n",
       "      <td>27625.0</td>\n",
       "      <td>189474.969209</td>\n",
       "      <td>Houston-Pasadena-The Woodlands, TX</td>\n",
       "      <td>29.8422</td>\n",
       "      <td>-95.3855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>517500.0</td>\n",
       "      <td>539900.0</td>\n",
       "      <td>217.805198</td>\n",
       "      <td>217.108051</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>531100.0</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>504649.454265</td>\n",
       "      <td>Baltimore-Columbia-Towson, MD</td>\n",
       "      <td>39.3386</td>\n",
       "      <td>-76.5807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>749000.0</td>\n",
       "      <td>749400.0</td>\n",
       "      <td>349.226265</td>\n",
       "      <td>339.058053</td>\n",
       "      <td>113.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>591100.0</td>\n",
       "      <td>16826.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>31591.0</td>\n",
       "      <td>31591.0</td>\n",
       "      <td>14740.0</td>\n",
       "      <td>699558.033278</td>\n",
       "      <td>Riverside-San Bernardino-Ontario, CA</td>\n",
       "      <td>34.5517</td>\n",
       "      <td>-116.1297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  median_sale_price  median_list_price  median_ppsf  \\\n",
       "0  2021-07-31           258528.0           259900.0   145.396160   \n",
       "1  2021-08-31           457000.0           429000.0   253.164135   \n",
       "2  2020-02-29           187250.0           202500.0    99.965760   \n",
       "3  2020-06-30           517500.0           539900.0   217.805198   \n",
       "4  2021-07-31           749000.0           749400.0   349.226265   \n",
       "\n",
       "   median_list_ppsf  homes_sold  pending_sales  new_listings  inventory  \\\n",
       "0        140.979244       104.0           98.0         107.0       66.0   \n",
       "1        257.973734        82.0           95.0         117.0      126.0   \n",
       "2        109.198464        94.0          115.0         140.0      157.0   \n",
       "3        217.108051         6.0           11.0          11.0       14.0   \n",
       "4        339.058053       113.0          112.0         140.0       60.0   \n",
       "\n",
       "   median_dom  ...  Median Home Value  Total Labor Force  \\\n",
       "0        48.0  ...           182900.0            10937.0   \n",
       "1        71.0  ...                0.0                0.0   \n",
       "2        47.5  ...           161000.0            31265.0   \n",
       "3        68.0  ...           531100.0             1251.0   \n",
       "4        18.0  ...           591100.0            16826.0   \n",
       "\n",
       "   Unemployed Population Total School Age Population  Total School Enrollment  \\\n",
       "0                  250.0                     20604.0                  20604.0   \n",
       "1                    0.0                         0.0                      0.0   \n",
       "2                 1746.0                     52357.0                  52357.0   \n",
       "3                   30.0                      1991.0                   1991.0   \n",
       "4                  681.0                     31591.0                  31591.0   \n",
       "\n",
       "   Median Commute Time          price                             city_full  \\\n",
       "0              10007.0  255300.562038                  Cincinnati, OH-KY-IN   \n",
       "1                  0.0  450603.296700    New York-Newark-Jersey City, NY-NJ   \n",
       "2              27625.0  189474.969209    Houston-Pasadena-The Woodlands, TX   \n",
       "3               1156.0  504649.454265         Baltimore-Columbia-Towson, MD   \n",
       "4              14740.0  699558.033278  Riverside-San Bernardino-Ontario, CA   \n",
       "\n",
       "       lat       lng  \n",
       "0  39.0811  -84.4646  \n",
       "1  40.7222  -74.0225  \n",
       "2  29.8422  -95.3855  \n",
       "3  39.3386  -76.5807  \n",
       "4  34.5517 -116.1297  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping lat/lng merge: already present in DataFrame.\n",
      "âœ… Dropped 0 duplicate rows (excluding date/year).\n",
      "âœ… Removed 0 rows with median_list_price > 19M.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['year', 'quarter', 'month', 'median_list_price', 'median_ppsf', 'median_list_ppsf', 'homes_sold', 'pending_sales', 'new_listings', 'inventory', 'median_dom', 'avg_sale_to_list', 'sold_above_list', 'off_market_in_two_weeks', 'bank', 'bus', 'hospital', 'mall', 'park', 'restaurant', 'school', 'station', 'supermarket', 'Total Population', 'Median Age', 'Per Capita Income', 'Total Families Below Poverty', 'Total Housing Units', 'Median Rent', 'Median Home Value', 'Total Labor Force', 'Unemployed Population', 'Total School Age Population', 'Total School Enrollment', 'Median Commute Time', 'lat', 'lng', 'zipcode_freq', 'city_encoded'] ['year', 'quarter', 'month', 'median_list_price', 'median_ppsf', 'median_list_ppsf', 'homes_sold', 'pending_sales', 'new_listings', 'inventory', 'median_dom', 'avg_sale_to_list', 'sold_above_list', 'off_market_in_two_weeks', 'bank', 'bus', 'hospital', 'mall', 'park', 'restaurant', 'school', 'station', 'supermarket', 'Total Population', 'Median Age', 'Per Capita Income', 'Total Families Below Poverty', 'Total Housing Units', 'Median Rent', 'Median Home Value', 'Total Labor Force', 'Unemployed Population', 'Total School Age Population', 'Total School Enrollment', 'Median Commute Time', 'lat', 'lng', 'zipcode_freq', 'city_full_encoded']\nexpected city_encoded in input data\ntraining data did not have the following fields: city_full_encoded",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m display(df.head())\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Run inference\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m preds_df = \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Predictions returned\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m display(preds_df[[\u001b[33m\"\u001b[39m\u001b[33mpredicted_price\u001b[39m\u001b[33m\"\u001b[39m]].head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Downloads\\machine learning\\project\\Regression_ML_EndtoEnd\\src\\inference_pipeline\\inference.py:89\u001b[39m, in \u001b[36mpredict\u001b[39m\u001b[34m(input_df, model_path, freq_encoder_path, target_encoder_path)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Step 6: Load model & predict\u001b[39;00m\n\u001b[32m     88\u001b[39m model = load(model_path)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m preds = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Step 7: Build output\u001b[39;00m\n\u001b[32m     92\u001b[39m out = df.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Downloads\\machine learning\\project\\Regression_ML_EndtoEnd\\.venv\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Downloads\\machine learning\\project\\Regression_ML_EndtoEnd\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1327\u001b[39m, in \u001b[36mXGBModel.predict\u001b[39m\u001b[34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[39m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._can_use_inplace_predict():\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1327\u001b[39m         predts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmargin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[32m   1336\u001b[39m             cp = import_cupy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Downloads\\machine learning\\project\\Regression_ML_EndtoEnd\\.venv\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Downloads\\machine learning\\project\\Regression_ML_EndtoEnd\\.venv\\Lib\\site-packages\\xgboost\\core.py:2667\u001b[39m, in \u001b[36mBooster.inplace_predict\u001b[39m\u001b[34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[39m\n\u001b[32m   2665\u001b[39m     data, fns, _ = _transform_pandas_df(data, enable_categorical)\n\u001b[32m   2666\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[32m-> \u001b[39m\u001b[32m2667\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2668\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[32m   2669\u001b[39m     data = np.array(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Downloads\\machine learning\\project\\Regression_ML_EndtoEnd\\.venv\\Lib\\site-packages\\xgboost\\core.py:3243\u001b[39m, in \u001b[36mBooster._validate_features\u001b[39m\u001b[34m(self, feature_names)\u001b[39m\n\u001b[32m   3237\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[32m   3238\u001b[39m     msg += (\n\u001b[32m   3239\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mtraining data did not have the following fields: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3240\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[32m   3241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m3243\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg.format(\u001b[38;5;28mself\u001b[39m.feature_names, feature_names))\n",
      "\u001b[31mValueError\u001b[39m: feature_names mismatch: ['year', 'quarter', 'month', 'median_list_price', 'median_ppsf', 'median_list_ppsf', 'homes_sold', 'pending_sales', 'new_listings', 'inventory', 'median_dom', 'avg_sale_to_list', 'sold_above_list', 'off_market_in_two_weeks', 'bank', 'bus', 'hospital', 'mall', 'park', 'restaurant', 'school', 'station', 'supermarket', 'Total Population', 'Median Age', 'Per Capita Income', 'Total Families Below Poverty', 'Total Housing Units', 'Median Rent', 'Median Home Value', 'Total Labor Force', 'Unemployed Population', 'Total School Age Population', 'Total School Enrollment', 'Median Commute Time', 'lat', 'lng', 'zipcode_freq', 'city_encoded'] ['year', 'quarter', 'month', 'median_list_price', 'median_ppsf', 'median_list_ppsf', 'homes_sold', 'pending_sales', 'new_listings', 'inventory', 'median_dom', 'avg_sale_to_list', 'sold_above_list', 'off_market_in_two_weeks', 'bank', 'bus', 'hospital', 'mall', 'park', 'restaurant', 'school', 'station', 'supermarket', 'Total Population', 'Median Age', 'Per Capita Income', 'Total Families Below Poverty', 'Total Housing Units', 'Median Rent', 'Median Home Value', 'Total Labor Force', 'Unemployed Population', 'Total School Age Population', 'Total School Enrollment', 'Median Commute Time', 'lat', 'lng', 'zipcode_freq', 'city_full_encoded']\nexpected city_encoded in input data\ntraining data did not have the following fields: city_full_encoded"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Force notebook to recognize project root\n",
    "import os\n",
    "ROOT = Path(os.getcwd()).resolve().parents[0] # one level up from tests/\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "import pandas as pd\n",
    "from src.inference_pipeline.inference import predict\n",
    "\n",
    "# Load a few rows of already preprocessed data\n",
    "sample_path = ROOT / \"data/processed/cleaning_eval.csv\"\n",
    "df = pd.read_csv(sample_path).sample(5, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Input sample:\")\n",
    "display(df.head())\n",
    "\n",
    "# Run inference\n",
    "preds_df = predict(df)\n",
    "print(\"âœ… Predictions returned\")\n",
    "display(preds_df[[\"predicted_price\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95924b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housing-regression-mle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
